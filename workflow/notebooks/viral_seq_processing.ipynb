{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viral sequence processing:\n",
    "\n",
    "Sequences need to be filtered on quality stats and get clustered at 95% ANI. Doing this with cdhit bc lazy and it works as well as drep. Using only sequences from the 338 'good' metagenomic datasets\n",
    "\n",
    "After clustering:\n",
    "- pangenomics\n",
    "- host linkages\n",
    "- AMGs (through VIBRANT)?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering and filtering viral sequences:\n",
    "- We have low, high and medium quality sequences. Since these come from metaGs, I only want to keep high and med quality. \n",
    "- Need to include all new vOTUs\n",
    "- Then cluster using CD-HIT: https://www.biostars.org/p/366171/ for full file names\n",
    "- full file names for pangenomics later\n",
    "- vOTUs can be used for AMGs, host linking\n",
    "- CLuster at 95% ANI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "# AMGS\n",
    "for AMGs:\n",
    "- Rerun VS2 with dramV setting\n",
    "- Run DRAM-V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Clustering and filtering for high-quality vOTUs\n",
    "\n",
    "# In: /group/ctbrowngrp2/scratch/annie/2024-pigparadigm/results/vOTUs/virsorter2\n",
    "# concatenate all viral score tsvs (n=111,082)\n",
    "mamba activate csvtk\n",
    "csvtk concat virsorter2/*/final-viral-score.tsv -t > virsorter2_viralscores.tsv\n",
    "\n",
    "# Rename the csv files with viral scores\n",
    "for f in virsorter2/*/final-viral-combined.fa\n",
    "do \n",
    "echo $f\n",
    "grep -e '>' $f > ./tsv_files/oldhead/${f%/*}.csv\n",
    "done\n",
    "\n",
    "# now for the renamed ones (renamed viral seqs because of spaces in names)\n",
    "for f in contigs/*rename.fa\n",
    "do\n",
    "echo $f\n",
    "grep -e '>' $f > ../header_files/newhead/${f%_rename*}.csv\n",
    "done\n",
    "\n",
    "# remove the carrots, in both oldhead and newhead folders\n",
    "for f in *.csv\n",
    "do\n",
    "sed 's/[<>,]//g' $f > ${f%.csv*}.clean.csv\n",
    "done\n",
    "\n",
    "# now make a concatenated file with names\n",
    "for f in *.clean.csv\n",
    "do\n",
    "paste -d \"\\t\" $f ../newhead/$f > ../combined_head/$f\n",
    "done\n",
    "\n",
    "# add header\n",
    "for f in *.csv\n",
    "do\n",
    "csvtk add-header -t $f -n seqname,newname > $f.newname\n",
    "done\n",
    "\n",
    "# concat all\n",
    "csvtk concat -t *.newname > ../header_keys.tsv\n",
    "\n",
    "# join the final csvs\n",
    "csvtk join -t -f seqname virsorter2_viralscores.tsv header_files/header_keys.tsv > renamed_viralscore.tsv\n",
    "\n",
    "# select for max_score => 0.9 (n=62,146)\n",
    "csvtk filter -f \"max_score>=0.9\" -t renamed_viralscore.tsv > highqual_renamed_viralscore.tsv\n",
    "csvtk filter -f \"length>=5000\" -t highqual_renamed_viralscore.tsv > highqual_renamed_viralscore.len.tsv\n",
    "\n",
    "\n",
    "# take the column with the new names so we can filter the fasta\n",
    "csvtk cut -f \"newname\" highqual_renamed_viralscore.len.tsv -t > highqual_namelist.txt\n",
    "\n",
    "# now use bbmap to filter fasta\n",
    "mamba activate bbmap \n",
    "filterbyname.sh in=hq_virseqs.fa out=hq_virseqs.len.fa names=./tsv_files/highqual_namelist.txt include=t\n",
    "\n",
    "# and sort it by length \n",
    "sortbyname.sh in=hq_virseqs.len.fa out=hq_virseqs.sort.fa length descending\n",
    "\n",
    "# now cdhit to deduplicate \n",
    "srun --account=ctbrowngrp -p bmm -J cdhit -t 5:00:00 -c 32 --mem=70gb --pty bash\n",
    "\n",
    "mamba activate cdhit\n",
    "cd-hit-est -i hq_virseqs.sort.fa \\\n",
    "-o hq_virseqs.95.cluster.fa -d 0 \\\n",
    "-c 0.95 -aS 0.85 -M 70000 -T 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pangenomics\n",
    "- Picked 10 clusters > 30 strains\n",
    "- Picked 10 metaGs to crosscheck\n",
    "- Use Snakefile_vir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# use snakemake\n",
    "# run snake \n",
    "srun --account=ctbrowngrp -p med2 -J snake -t 20:00:00 -c 40 --mem=20gb --pty bash\n",
    "mamba activate branchwater\n",
    "\n",
    "snakemake -s Snakefile_vir_tax --use-conda --resources mem_mb=20000 --rerun-triggers mtime \\\n",
    "-c 40 --rerun-incomplete -k -n\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taxonomy\n",
    "- Use sourmash for the viral taxonomy\n",
    "- Use genomad for taxonomy\n",
    "- Compare output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#GENOMAD\n",
    "# srun it, needs quite some mem\n",
    "srun --account=ctbrowngrp -p med2 -J genomad -t 24:00:00 -c 36 --mem=80gb --pty bash\n",
    "\n",
    "# end to end for everything, need to annotate for classification\n",
    "# Use for taxonomy of DNA phage\n",
    "\n",
    "mamba activate genomad\n",
    "genomad end-to-end \\\n",
    "hq_virseqs.95.cluster.fa \\\n",
    "./genomad /group/jbemersogrp/databases/genomad/genomad_db \\\n",
    "--threads 36 --enable-score-calibration \\\n",
    "--splits 20 --cleanup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Find the sourmash code tomorrow\n",
    "# Sourmash\n",
    "# Split into individ\n",
    "awk '/^>/ {OUT=substr($0,2) \".fa\"}; OUT {print >OUT}'  ../hq_virseqs.95.cluster.fa\n",
    "# sketch contigs\n",
    "# Use fastgather -> ICTV\n",
    "# Then sourmash tax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "srun --account=ctbrowngrp -p med2 -J fmg -t 24:00:00 -c 50 --mem=60gb --pty bash\n",
    "\n",
    "\n",
    "# can I do a fmg against ICTV??\n",
    "sourmash scripts fastmultigather \\\n",
    "../vOTU_sketchpaths.txt \\\n",
    "/home/ntpierce/2023-spillover/output.vmr/vmr_MSL38_v1.dna.k21.zip \\\n",
    "-k 21 --scaled 100 -t 100 -m DNA -c 50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# tax annotate\n",
    "sourmash tax annotate --from-file fmg_out.txt \\\n",
    "-t /home/ntpierce/2023-spillover/output.vmr/vmr_MSL38_v1.taxonomy.csv \\\n",
    "-o fmg_tax --ictv\n",
    "\n",
    "# tax genome \n",
    "sourmash tax genome -q --from-file fmg_out.txt -r family \\\n",
    "-t /home/ntpierce/2023-spillover/output.vmr/vmr_MSL38_v1.taxonomy.csv \\\n",
    "--output-dir fmg_tax_genome --ictv -o fmg_tax_genome_fam"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
